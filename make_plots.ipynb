{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import pytz\n",
    "import datetime\n",
    "from datetime import timezone\n",
    "from numpy import trapz\n",
    "import numpy as np\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../grafana_data/exp_multiple_workers_2/'\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = data_dir + 'dejan-resnet50-256-ps-16-workers-16.csv'\n",
    "gpu_info = pd.read_csv(filepath)\n",
    "gpu_info['gpu-utilization'] = gpu_info['gpu-utilization'].astype(object)\n",
    "gpu_info['gpu-memory'] = gpu_info['gpu-memory'].astype(object)\n",
    "gpu_info['gpu-power-usage'] = gpu_info['gpu-power-usage'].astype(object)\n",
    "gpu_info['gpu-temperature'] = gpu_info['gpu-temperature'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_power_usage = pd.read_csv(data_dir + 'grafana_gpu_power_usage.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_utilization = pd.read_csv(data_dir + 'grafana_gpu_utilization.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_memory = pd.read_csv(data_dir + 'grafana_gpu_memory.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_temperature = pd.read_csv(data_dir + 'grafana_gpu_temperature.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grafana_info(gpu_info, grafana_df, tolerance_min=15):\n",
    "    grafana_df['Time'] = pd.to_datetime(grafana_df['Time'], format='%Y-%m-%dT%H:%M:%S')\n",
    "    grafana_df['Time'] = grafana_df['Time'].dt.tz_convert(tz='Etc/GMT-2')\n",
    "\n",
    "    start_time = pd.date_range(gpu_info['start-time'], periods=1) + pd.Timedelta(minutes=-tolerance_min)\n",
    "    end_time = pd.date_range(gpu_info['end-time'], periods=1) + pd.Timedelta(minutes=tolerance_min)\n",
    "\n",
    "    new_start = pd.date_range(start_time[0].replace(tzinfo=timezone.utc), periods=1)\n",
    "    new_end = pd.date_range(end_time[0].replace(tzinfo=timezone.utc), periods=1)\n",
    "    \n",
    "    res_df = grafana_df.loc[(grafana_df['Series'] == gpu_info['nvidia-plugins'] + '-gpu0') & \\\n",
    "                            (grafana_df['Time'] > new_start[0]) & \\\n",
    "                            (grafana_df['Time'] <= new_end[0])]\n",
    "    \n",
    "    values = res_df['Value'].values\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_grafana_info(values, label='info'):\n",
    "    if all(v == 0 for v in values):\n",
    "        print('\\tERROR')\n",
    "    else:\n",
    "        print('\\t' + label + ' = ' + str(max(values)))\n",
    "\n",
    "for index, row in gpu_info.iterrows():\n",
    "    print(row['model'], row['batch-size'], row['nvidia-plugins'])\n",
    "    tolerance_min = 10\n",
    "    \n",
    "    gpu_utilization = get_grafana_info(row, grafana_gpu_utilization, tolerance_min)\n",
    "    print_grafana_info(gpu_utilization, 'gpu_utilization')\n",
    "    gpu_info.at[index, 'gpu-utilization'] = gpu_utilization\n",
    "    \n",
    "    gpu_memory = get_grafana_info(row, grafana_gpu_memory)\n",
    "    print_grafana_info(gpu_memory, 'gpu_memory')\n",
    "    gpu_info.at[index, 'gpu-memory'] = gpu_memory\n",
    "        \n",
    "    gpu_power_usage = get_grafana_info(row, grafana_gpu_power_usage, tolerance_min)\n",
    "    print_grafana_info(gpu_power_usage, 'gpu_power_usage')\n",
    "    gpu_info.at[index, 'gpu-power-usage'] = gpu_power_usage\n",
    "    \n",
    "    gpu_temperature = get_grafana_info(row, grafana_gpu_temperature, tolerance_min)\n",
    "    print_grafana_info(gpu_temperature, 'gpu_temperature')\n",
    "    gpu_info.at[index, 'gpu-temperature'] = gpu_temperature\n",
    "        \n",
    "    print()\n",
    "\n",
    "outpath = 'experiments-with-grafana.csv'\n",
    "gpu_info.to_csv(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_info_full = pd.read_csv(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(string, f=lambda x:float(x)):\n",
    "    lst = str(string[1:-1]).split()\n",
    "    return [f(x) for x in lst]\n",
    "\n",
    "def get_max(model, column):\n",
    "    model_df = gpu_info_full.loc[(gpu_info_full['model'] == model)].sort_values(by=['batch-size'])\n",
    "    res = []\n",
    "    x_axis = []\n",
    "    for index, row in model_df.iterrows():\n",
    "        res.append(max(get_list(model_df.at[index, column])))\n",
    "        x_axis.append(model_df.at[index, 'batch-size'])\n",
    "    \n",
    "    return res, x_axis\n",
    "\n",
    "titles = {'gpu-power-usage': 'Power', \\\n",
    "          'gpu-utilization': 'Utilization', \\\n",
    "          'gpu-memory': 'Memory', \\\n",
    "          'gpu-temperature': 'Temperature'}\n",
    "\n",
    "units = {'gpu-power-usage': '[mW]', \\\n",
    "          'gpu-utilization': '[%]', \\\n",
    "          'gpu-memory': '[%]', \\\n",
    "          'gpu-temperature': '[C]'}\n",
    "\n",
    "def scatter_all_max(column):\n",
    "    alexnet_max_power, alexnet_xaxis = get_max('alexnet', column)\n",
    "    resnet_max_power, resnset_xaxis = get_max('resnet50', column)\n",
    "    inception_max_power, inception_xaxis = get_max('inception4', column)\n",
    "    \n",
    "    x_alexnet = np.arange(len(alexnet_max_power))\n",
    "    x_resnet = np.arange(len(resnet_max_power))\n",
    "    x_inception = np.arange(len(inception_max_power))\n",
    "    \n",
    "    plt.bar(x_alexnet - 0.2, alexnet_max_power, width=0.2)\n",
    "    plt.bar(x_resnet, resnet_max_power, width=0.2)\n",
    "    plt.bar(x_inception + 0.2, inception_max_power, width=0.2)\n",
    "    plt.legend(['alexnet', 'resnet', 'inception'])\n",
    "    plt.xticks(np.arange(len(alexnet_xaxis)), alexnet_xaxis)\n",
    "    plt.xlabel('Batch Size')\n",
    "    plt.title('GPU ' + titles[column] + ' ' + units[column] + ', Workers = 1, ' + 'PS = 1')\n",
    "    \n",
    "    #plt.savefig('plots/' + column + '-ps-16-workers-16.jpg', dpi=128)\n",
    "    plt.show()\n",
    "    \n",
    "scatter_all_max('gpu-power-usage')\n",
    "scatter_all_max('gpu-utilization')\n",
    "scatter_all_max('gpu-memory')\n",
    "scatter_all_max('gpu-temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "gitlab-registry.cern.ch/ai-ml/images/kale-custom",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
