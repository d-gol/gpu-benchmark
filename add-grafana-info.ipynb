{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_date(original_date, part_to_mod='sec', amount='0', func=lambda a,b:a):\n",
    "    i = 0 if part_to_mod=='hour' else 1 if part_to_mod=='min' else 2\n",
    "    \n",
    "    splits = original_date.split('T')\n",
    "    time_parts = splits[1].split(':')\n",
    "    time_parts[i] = str(func(int(time_parts[i]), amount))\n",
    "    \n",
    "    return splits[0] + 'T' + time_parts[0] + ':' + time_parts[1] + ':' + time_parts[2]\n",
    "    \n",
    "def add_hours(original_date, n=0):\n",
    "    return modify_date(original_date, 'hour', n, lambda a,b:a + b)\n",
    "\n",
    "def add_minutes(original_date, n=0):   \n",
    "    return modify_date(original_date, 'min', n, lambda a,b:a + b)\n",
    "\n",
    "def sub_minutes(original_date, n=0):   \n",
    "    return modify_date(original_date, 'min', n, lambda a,b:a - b)\n",
    "\n",
    "def add_seconds(original_date, n=0):   \n",
    "    return modify_date(original_date, 'sec', n, lambda a,b:a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_info = pd.read_csv('experiments.csv', index_col='id')\n",
    "gpu_info['gpu-utilization'] = gpu_info['gpu-utilization'].astype(object)\n",
    "gpu_info['gpu-memory'] = gpu_info['gpu-memory'].astype(object)\n",
    "gpu_info['gpu-power-usage'] = gpu_info['gpu-power-usage'].astype(object)\n",
    "gpu_info['gpu-temperature'] = gpu_info['gpu-temperature'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_power_usage = pd.read_csv('grafana_gpu_power_usage.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_utilization = pd.read_csv('grafana_gpu_utilization.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_memory = pd.read_csv('grafana_gpu_memory.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_temperature = pd.read_csv('grafana_gpu_temperature.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import datetime\n",
    "from datetime import timezone\n",
    "from numpy import trapz\n",
    "import numpy as np\n",
    "\n",
    "def get_grafana_info(gpu_info, grafana_df, tolerance_min=15):\n",
    "    grafana_df['Time'] = pd.to_datetime(grafana_df['Time'], format='%Y-%m-%dT%H:%M:%S')\n",
    "    grafana_df['Time'] = grafana_df['Time'].dt.tz_convert(tz='Etc/GMT-2')\n",
    "\n",
    "    start_time = pd.date_range(gpu_info['start-time'], periods=1) + pd.Timedelta(minutes=-tolerance_min)\n",
    "    end_time = pd.date_range(gpu_info['end-time'], periods=1) + pd.Timedelta(minutes=tolerance_min)\n",
    "\n",
    "    new_start = pd.date_range(start_time[0].replace(tzinfo=timezone.utc), periods=1)\n",
    "    new_end = pd.date_range(end_time[0].replace(tzinfo=timezone.utc), periods=1)\n",
    "    \n",
    "    res_df = grafana_df.loc[(grafana_df['Series'] == gpu_info['nvidia-plugins'] + '-gpu0') & \\\n",
    "                            (grafana_df['Time'] > new_start[0]) & \\\n",
    "                            (grafana_df['Time'] <= new_end[0])]\n",
    "    \n",
    "    values = res_df['Value'].values\n",
    "    print(len(values))\n",
    "    \n",
    "    #plt.plot(range(0, len(values)), values)\n",
    "    #plt.show()\n",
    "    \n",
    "    area = trapz(values, range(0, len(values)), 1)\n",
    "    print(\"\\tarea =\", area)\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet 32 nvidia-gpu-device-plugin-j8nl9\n",
      "31\n",
      "\tarea = 60.0\n",
      "\tgpu_utilization = 60.0\n",
      "31\n",
      "\tarea = 479.497008658741\n",
      "\tgpu_memory = 95.37514802909828\n",
      "62\n",
      "\tarea = 1801312.5\n",
      "\tgpu_power_usage = 53985.0\n",
      "62\n",
      "\tarea = 2188.5\n",
      "\tgpu_temperature = 43.0\n",
      "\n",
      "alexnet 32 nvidia-gpu-device-plugin-sn4v2\n",
      "33\n",
      "\tarea = 6.0\n",
      "\tgpu_utilization = 6.0\n",
      "33\n",
      "\tarea = 670.2473047169376\n",
      "\tgpu_memory = 95.37514802909828\n",
      "65\n",
      "\tarea = 1908229.0\n",
      "\tgpu_power_usage = 41608.0\n",
      "65\n",
      "\tarea = 2069.0\n",
      "\tgpu_temperature = 34.0\n",
      "\n",
      "inception 32 nvidia-gpu-device-plugin-kcqcb\n",
      "31\n",
      "\tarea = 98.0\n",
      "\tgpu_utilization = 98.0\n",
      "31\n",
      "\tarea = 479.50316051737127\n",
      "\tgpu_memory = 95.37514802909828\n",
      "61\n",
      "\tarea = 2010408.5\n",
      "\tgpu_power_usage = 255608.0\n",
      "61\n",
      "\tarea = 1990.0\n",
      "\tgpu_temperature = 49.0\n",
      "\n",
      "resnet 64 nvidia-gpu-device-plugin-j8nl9\n",
      "31\n",
      "\tarea = 0.0\n",
      "\tERROR\n",
      "31\n",
      "\tarea = 478.15936389781757\n",
      "\tgpu_memory = 95.35054059457714\n",
      "61\n",
      "\tarea = 1850294.5\n",
      "\tgpu_power_usage = 169985.0\n",
      "61\n",
      "\tarea = 2156.5\n",
      "\tgpu_temperature = 48.0\n",
      "\n",
      "alexnet 64 nvidia-gpu-device-plugin-bdtt6\n",
      "33\n",
      "\tarea = 0.0\n",
      "\tERROR\n",
      "33\n",
      "\tarea = 670.0750526752895\n",
      "\tgpu_memory = 95.37514802909828\n",
      "65\n",
      "\tarea = 1835669.5\n",
      "\tgpu_power_usage = 35903.0\n",
      "65\n",
      "\tarea = 1896.0\n",
      "\tgpu_temperature = 31.0\n",
      "\n",
      "inception 64 nvidia-gpu-device-plugin-25ts6\n",
      "32\n",
      "\tarea = 197.0\n",
      "\tgpu_utilization = 99.0\n",
      "32\n",
      "\tarea = 668.9156195690623\n",
      "\tgpu_memory = 95.37514802909828\n",
      "64\n",
      "\tarea = 2561900.0\n",
      "\tgpu_power_usage = 224642.0\n",
      "64\n",
      "\tarea = 1954.0\n",
      "\tgpu_temperature = 49.0\n",
      "\n",
      "resnet 128 nvidia-gpu-device-plugin-mw5pt\n",
      "31\n",
      "\tarea = 99.0\n",
      "\tgpu_utilization = 99.0\n",
      "31\n",
      "\tarea = 958.8836683533012\n",
      "\tgpu_memory = 95.38129988772856\n",
      "62\n",
      "\tarea = 2211295.5\n",
      "\tgpu_power_usage = 220230.0\n",
      "62\n",
      "\tarea = 2016.0\n",
      "\tgpu_temperature = 54.0\n",
      "\n",
      "alexnet 128 nvidia-gpu-device-plugin-fjp6k\n",
      "33\n",
      "\tarea = 14.0\n",
      "\tgpu_utilization = 9.0\n",
      "33\n",
      "\tarea = 911.5041678842219\n",
      "\tgpu_memory = 95.38129988772856\n",
      "66\n",
      "\tarea = 2092358.5\n",
      "\tgpu_power_usage = 41806.0\n",
      "66\n",
      "\tarea = 2223.0\n",
      "\tgpu_temperature = 36.0\n",
      "\n",
      "inception 128 nvidia-gpu-device-plugin-sn4v2\n",
      "32\n",
      "\tarea = 214.0\n",
      "\tgpu_utilization = 100.0\n",
      "32\n",
      "\tarea = 765.339082757878\n",
      "\tgpu_memory = 95.37514802909828\n",
      "65\n",
      "\tarea = 3087605.0\n",
      "\tgpu_power_usage = 252247.0\n",
      "65\n",
      "\tarea = 2208.0\n",
      "\tgpu_temperature = 58.0\n",
      "\n",
      "resnet 256 nvidia-gpu-device-plugin-k6jh2\n",
      "32\n",
      "\tarea = 198.0\n",
      "\tgpu_utilization = 100.0\n",
      "32\n",
      "\tarea = 574.8783085464695\n",
      "\tgpu_memory = 95.37514802909828\n",
      "64\n",
      "\tarea = 2460233.0\n",
      "\tgpu_power_usage = 228526.0\n",
      "64\n",
      "\tarea = 2130.0\n",
      "\tgpu_temperature = 55.0\n",
      "\n",
      "alexnet 256 nvidia-gpu-device-plugin-fjp6k\n",
      "32\n",
      "\tarea = 4.0\n",
      "\tgpu_utilization = 3.0\n",
      "32\n",
      "\tarea = 910.2216976053891\n",
      "\tgpu_memory = 95.38129988772856\n",
      "65\n",
      "\tarea = 2215060.5\n",
      "\tgpu_power_usage = 140986.0\n",
      "65\n",
      "\tarea = 2200.5\n",
      "\tgpu_temperature = 37.0\n",
      "\n",
      "alexnet 512 nvidia-gpu-device-plugin-fjp6k\n",
      "33\n",
      "\tarea = 62.0\n",
      "\tgpu_utilization = 56.0\n",
      "33\n",
      "\tarea = 764.4199566293967\n",
      "\tgpu_memory = 95.38129988772856\n",
      "66\n",
      "\tarea = 2090562.0\n",
      "\tgpu_power_usage = 107544.0\n",
      "66\n",
      "\tarea = 2239.0\n",
      "\tgpu_temperature = 39.0\n",
      "\n",
      "alexnet 1024 nvidia-gpu-device-plugin-sn4v2\n",
      "33\n",
      "\tarea = 30.0\n",
      "\tgpu_utilization = 30.0\n",
      "33\n",
      "\tarea = 764.3830454776149\n",
      "\tgpu_memory = 95.38745174635885\n",
      "66\n",
      "\tarea = 2333475.5\n",
      "\tgpu_power_usage = 253805.0\n",
      "66\n",
      "\tarea = 2134.5\n",
      "\tgpu_temperature = 40.0\n",
      "\n",
      "alexnet 2048 nvidia-gpu-device-plugin-j8nl9\n",
      "33\n",
      "\tarea = 192.0\n",
      "\tgpu_utilization = 100.0\n",
      "33\n",
      "\tarea = 765.5607419141509\n",
      "\tgpu_memory = 95.39975546361946\n",
      "66\n",
      "\tarea = 2381559.0\n",
      "\tgpu_power_usage = 251548.0\n",
      "66\n",
      "\tarea = 2375.0\n",
      "\tgpu_temperature = 47.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_grafana_info(values, label='info'):\n",
    "    if all(v == 0 for v in values):\n",
    "        print('\\tERROR')\n",
    "    else:\n",
    "        print('\\t' + label + ' = ' + str(max(values)))\n",
    "\n",
    "for index, row in gpu_info.iterrows():\n",
    "    print(row['network'], row['batch-size'], row['nvidia-plugins'])\n",
    "    tolerance_min = 15\n",
    "    \n",
    "    gpu_utilization = get_grafana_info(row, grafana_gpu_utilization, tolerance_min)\n",
    "    print_grafana_info(gpu_utilization, 'gpu_utilization')\n",
    "    gpu_info.at[index, 'gpu-utilization'] = gpu_utilization\n",
    "    \n",
    "    gpu_memory = get_grafana_info(row, grafana_gpu_memory)\n",
    "    print_grafana_info(gpu_memory, 'gpu_memory')\n",
    "    gpu_info.at[index, 'gpu-memory'] = gpu_memory\n",
    "        \n",
    "    gpu_power_usage = get_grafana_info(row, grafana_gpu_power_usage, tolerance_min)\n",
    "    print_grafana_info(gpu_power_usage, 'gpu_power_usage')\n",
    "    gpu_info.at[index, 'gpu-power-usage'] = gpu_power_usage\n",
    "    \n",
    "    gpu_temperature = get_grafana_info(row, grafana_gpu_temperature, tolerance_min)\n",
    "    print_grafana_info(gpu_temperature, 'gpu_temperature')\n",
    "    gpu_info.at[index, 'gpu-temperature'] = gpu_temperature\n",
    "        \n",
    "    print()\n",
    "\n",
    "gpu_info.to_csv('experiments-with-grafana.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "gitlab-registry.cern.ch/ai-ml/images/kale-custom",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
