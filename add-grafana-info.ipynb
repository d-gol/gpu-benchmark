{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hours(original_date, n=2):\n",
    "    splits = original_date.split('T')\n",
    "    time_parts = splits[1].split(':')\n",
    "    new_hour = int(time_parts[0]) + n\n",
    "    \n",
    "    return splits[0] + 'T' + str(new_hour) + ':' + time_parts[1] + ':' + time_parts[2]\n",
    "\n",
    "def add_minutes(original_date, n=2):\n",
    "    splits = original_date.split('T')\n",
    "    time_parts = splits[1].split(':')\n",
    "    new_min = int(time_parts[1]) + n\n",
    "    \n",
    "    return splits[0] + 'T' + time_parts[0] + ':' + str(new_min)  + ':' + time_parts[2]\n",
    "\n",
    "def subtract_minutes(original_date, n=2):\n",
    "    splits = original_date.split('T')\n",
    "    time_parts = splits[1].split(':')\n",
    "    new_min = int(time_parts[1]) - n\n",
    "    \n",
    "    return splits[0] + 'T' + time_parts[0] + ':' + str(new_min)  + ':' + time_parts[2]\n",
    "\n",
    "def add_seconds(original_date, n=2):\n",
    "    splits = original_date.split('T')\n",
    "    time_parts = splits[1].split(':')\n",
    "    new_sec = int(time_parts[2]) + n\n",
    "    \n",
    "    return splits[0] + 'T' + time_parts[0] + ':' + time_parts[1] + ':' + str(new_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_info = pd.read_csv('experiments.csv', index_col='id')\n",
    "\n",
    "for index, row in gpu_info.iterrows():\n",
    "    gpu_info.at[index,'start-time'] = add_hours(row['start-time'], 2)\n",
    "    gpu_info.at[index,'end-time'] = add_hours(row['end-time'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_power_usage = pd.read_csv('grafana_gpu_power_usage.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_utilization = pd.read_csv('grafana_gpu_utilization.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_memory = pd.read_csv('grafana_gpu_memory.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 60.  0.  0.\n",
      "  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "def get_grafana_info(nvidia_plugin, start_time, end_time, grafana_df, tolerance_min=15):\n",
    "    start_time = subtract_minutes(start_time, tolerance_min)\n",
    "    end_time = add_minutes(end_time, tolerance_min)\n",
    "    res_df = grafana_df.loc[(grafana_df['Series'] == nvidia_plugin) & \\\n",
    "                            (grafana_df['Time'] > start_time) & \\\n",
    "                            (grafana_df['Time'] <= end_time)]\n",
    "    values = res_df['Value'].values\n",
    "    #plt.scatter(range(0, len(values)), values)\n",
    "    #plt.show()\n",
    "    return values\n",
    "    \n",
    "print(get_grafana_info('nvidia-gpu-device-plugin-j8nl9' + '-gpu0', \n",
    "                       '2020-09-09T13:51:13',\n",
    "                       '2020-09-09T13:52:03',\n",
    "                       grafana_gpu_utilization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet 32\n",
      "GPU_util = 60.0\n",
      "MEM = 95.37514802909828\n",
      "Power = 53985.0\n",
      "\n",
      "alexnet 32\n",
      "GPU_util = 6.0\n",
      "MEM = 95.37514802909828\n",
      "Power = 41608.0\n",
      "\n",
      "inception 32\n",
      "GPU_util = 98.0\n",
      "MEM = 95.37514802909828\n",
      "Power = 255608.0\n",
      "\n",
      "resnet 64\n",
      "ERROR\n",
      "MEM = 95.35054059457714\n",
      "Power = 169985.0\n",
      "\n",
      "alexnet 64\n",
      "ERROR\n",
      "MEM = 95.37514802909828\n",
      "Power = 35903.0\n",
      "\n",
      "inception 64\n",
      "GPU_util = 99.0\n",
      "MEM = 95.37514802909828\n",
      "Power = 224642.0\n",
      "\n",
      "resnet 128\n",
      "GPU_util = 99.0\n",
      "MEM = 95.38129988772856\n",
      "Power = 220230.0\n",
      "\n",
      "alexnet 128\n",
      "GPU_util = 9.0\n",
      "MEM = 95.38129988772856\n",
      "Power = 41806.0\n",
      "\n",
      "inception 128\n",
      "GPU_util = 100.0\n",
      "MEM = 95.37514802909828\n",
      "Power = 252247.0\n",
      "\n",
      "resnet 256\n",
      "GPU_util = 100.0\n",
      "MEM = 95.37514802909828\n",
      "Power = 228526.0\n",
      "\n",
      "alexnet 256\n",
      "GPU_util = 3.0\n",
      "MEM = 95.38129988772856\n",
      "Power = 140986.0\n",
      "\n",
      "alexnet 512\n",
      "GPU_util = 56.0\n",
      "MEM = 95.38129988772856\n",
      "Power = 107544.0\n",
      "\n",
      "alexnet 1024\n",
      "GPU_util = 30.0\n",
      "MEM = 95.38745174635885\n",
      "Power = 253805.0\n",
      "\n",
      "alexnet 2048\n",
      "GPU_util = 100.0\n",
      "MEM = 95.39975546361946\n",
      "Power = 251548.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in gpu_info.iterrows():\n",
    "    print(row['network'], row['batch-size'])\n",
    "    gpu_util = get_grafana_info(row['nvidia-plugins'] + '-gpu0', \\\n",
    "                                row['start-time'], \\\n",
    "                                row['end-time'], \\\n",
    "                                grafana_gpu_utilization)\n",
    "    if all(v == 0 for v in gpu_util):\n",
    "        print('ERROR')\n",
    "    else:\n",
    "        print('GPU_util = ' + str(max(gpu_util)))\n",
    "        \n",
    "    gpu_util = get_grafana_info(row['nvidia-plugins'] + '-gpu0', \\\n",
    "                                row['start-time'], \\\n",
    "                                row['end-time'], \\\n",
    "                                grafana_gpu_memory)\n",
    "    if all(v == 0 for v in gpu_util):\n",
    "        print('ERROR')\n",
    "    else:\n",
    "        print('MEM = ' + str(max(gpu_util)))\n",
    "        \n",
    "    gpu_util = get_grafana_info(row['nvidia-plugins'] + '-gpu0', \\\n",
    "                                row['start-time'], \\\n",
    "                                row['end-time'], \\\n",
    "                                grafana_gpu_power_usage)\n",
    "    if all(v == 0 for v in gpu_util):\n",
    "        print('ERROR')\n",
    "    else:\n",
    "        print('Power = ' + str(max(gpu_util)))\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "gitlab-registry.cern.ch/ai-ml/images/kale-custom",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
