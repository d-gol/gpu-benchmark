{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "gpu_info = pd.read_csv(data_dir + 'experiments.csv')\n",
    "gpu_info['gpu-utilization'] = gpu_info['gpu-utilization'].astype(object)\n",
    "gpu_info['gpu-memory'] = gpu_info['gpu-memory'].astype(object)\n",
    "gpu_info['gpu-power-usage'] = gpu_info['gpu-power-usage'].astype(object)\n",
    "gpu_info['gpu-temperature'] = gpu_info['gpu-temperature'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_power_usage = pd.read_csv(data_dir + 'grafana_gpu_power_usage.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_utilization = pd.read_csv(data_dir + 'grafana_gpu_utilization.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_memory = pd.read_csv(data_dir + 'grafana_gpu_memory.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_gpu_temperature = pd.read_csv(data_dir + 'grafana_gpu_temperature.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import datetime\n",
    "from datetime import timezone\n",
    "from numpy import trapz\n",
    "import numpy as np\n",
    "\n",
    "def get_grafana_info(gpu_info, grafana_df, tolerance_min=15):\n",
    "    grafana_df['Time'] = pd.to_datetime(grafana_df['Time'], format='%Y-%m-%dT%H:%M:%S')\n",
    "    grafana_df['Time'] = grafana_df['Time'].dt.tz_convert(tz='Etc/GMT-2')\n",
    "\n",
    "    start_time = pd.date_range(gpu_info['start-time'], periods=1) + pd.Timedelta(minutes=-tolerance_min)\n",
    "    end_time = pd.date_range(gpu_info['end-time'], periods=1) + pd.Timedelta(minutes=tolerance_min)\n",
    "\n",
    "    new_start = pd.date_range(start_time[0].replace(tzinfo=timezone.utc), periods=1)\n",
    "    new_end = pd.date_range(end_time[0].replace(tzinfo=timezone.utc), periods=1)\n",
    "    \n",
    "    res_df = grafana_df.loc[(grafana_df['Series'] == gpu_info['nvidia-plugins'] + '-gpu0') & \\\n",
    "                            (grafana_df['Time'] > new_start[0]) & \\\n",
    "                            (grafana_df['Time'] <= new_end[0])]\n",
    "    \n",
    "    values = res_df['Value'].values\n",
    "    print('\\t' + str(len(values)))\n",
    "    \n",
    "    #plt.plot(range(0, len(values)), values)\n",
    "    #plt.show()\n",
    "    \n",
    "    area = trapz(values, range(0, len(values)), 1)\n",
    "    print(\"\\tarea =\", area)\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet 1024 nvidia-gpu-device-plugin-k6jh2\n",
      "\t134\n",
      "\tarea = 122.0\n",
      "\tgpu_utilization = 49\n",
      "\t134\n",
      "\tarea = 3263.134410421248\n",
      "\tgpu_memory = 95.38745174635885\n",
      "\t134\n",
      "\tarea = 4250090.5\n",
      "\tgpu_power_usage = 54839\n",
      "\t134\n",
      "\tarea = 4392.0\n",
      "\tgpu_temperature = 38\n",
      "\n",
      "alexnet 128 nvidia-gpu-device-plugin-lbhl2\n",
      "\t135\n",
      "\tarea = 0.0\n",
      "\tERROR\n",
      "\t135\n",
      "\tarea = 3452.8834914873646\n",
      "\tgpu_memory = 95.38129988772856\n",
      "\t135\n",
      "\tarea = 3933168.0\n",
      "\tgpu_power_usage = 35978\n",
      "\t135\n",
      "\tarea = 4097.5\n",
      "\tgpu_temperature = 32\n",
      "\n",
      "alexnet 2048 nvidia-gpu-device-plugin-mw5pt\n",
      "\t136\n",
      "\tarea = 260.0\n",
      "\tgpu_utilization = 100\n",
      "\t136\n",
      "\tarea = 3456.892196367327\n",
      "\tgpu_memory = 95.39975546361946\n",
      "\t136\n",
      "\tarea = 5512866.0\n",
      "\tgpu_power_usage = 291186\n",
      "\t136\n",
      "\tarea = 4449.0\n",
      "\tgpu_temperature = 41\n",
      "\n",
      "alexnet 256 nvidia-gpu-device-plugin-j8nl9\n",
      "\t133\n",
      "\tarea = 18.0\n",
      "\tgpu_utilization = 9\n",
      "\t133\n",
      "\tarea = 3059.8022177450357\n",
      "\tgpu_memory = 95.38129988772856\n",
      "\t133\n",
      "\tarea = 4047415.0\n",
      "\tgpu_power_usage = 58098\n",
      "\t133\n",
      "\tarea = 4778.0\n",
      "\tgpu_temperature = 39\n",
      "\n",
      "alexnet 32 nvidia-gpu-device-plugin-j4xh9\n",
      "\t135\n",
      "\tarea = 6.0\n",
      "\tgpu_utilization = 2\n",
      "\t135\n",
      "\tarea = 3451.9980083357677\n",
      "\tgpu_memory = 95.37514802909828\n",
      "\t135\n",
      "\tarea = 4040159.5\n",
      "\tgpu_power_usage = 52877\n",
      "\t135\n",
      "\tarea = 4367.0\n",
      "\tgpu_temperature = 34\n",
      "\n",
      "alexnet 512 nvidia-gpu-device-plugin-25ts6\n",
      "\t135\n",
      "\tarea = 52.0\n",
      "\tgpu_utilization = 25\n",
      "\t135\n",
      "\tarea = 3263.6390550745136\n",
      "\tgpu_memory = 95.38129988772856\n",
      "\t135\n",
      "\tarea = 4102140.5\n",
      "\tgpu_power_usage = 48734\n",
      "\t135\n",
      "\tarea = 4060.0\n",
      "\tgpu_temperature = 34\n",
      "\n",
      "alexnet 64 nvidia-gpu-device-plugin-jzgnl\n",
      "\t136\n",
      "\tarea = 52.0\n",
      "\tgpu_utilization = 21\n",
      "\t136\n",
      "\tarea = 3441.46391165931\n",
      "\tgpu_memory = 95.37514802909828\n",
      "\t136\n",
      "\tarea = 3868304.5\n",
      "\tgpu_power_usage = 37150\n",
      "\t136\n",
      "\tarea = 4759.0\n",
      "\tgpu_temperature = 38\n",
      "\n",
      "inception4 128 nvidia-gpu-device-plugin-q8cmp\n",
      "\t134\n",
      "\tarea = 814.0\n",
      "\tgpu_utilization = 100\n",
      "\t134\n",
      "\tarea = 3263.944725550206\n",
      "\tgpu_memory = 95.37514802909828\n",
      "\t134\n",
      "\tarea = 5520027.5\n",
      "\tgpu_power_usage = 250034\n",
      "\t134\n",
      "\tarea = 4822.0\n",
      "\tgpu_temperature = 55\n",
      "\n",
      "inception4 32 nvidia-gpu-device-plugin-7cmpw\n",
      "\t131\n",
      "\tarea = 450.0\n",
      "\tgpu_utilization = 98\n",
      "\t131\n",
      "\tarea = 2881.68322541948\n",
      "\tgpu_memory = 95.37514802909828\n",
      "\t131\n",
      "\tarea = 5146640.5\n",
      "\tgpu_power_usage = 244395\n",
      "\t131\n",
      "\tarea = 4074.0\n",
      "\tgpu_temperature = 41\n",
      "\n",
      "inception4 64 nvidia-gpu-device-plugin-pkrr4\n",
      "\t132\n",
      "\tarea = 512.0\n",
      "\tgpu_utilization = 99\n",
      "\t132\n",
      "\tarea = 3070.2501884006706\n",
      "\tgpu_memory = 95.37514802909828\n",
      "\t132\n",
      "\tarea = 4927014.0\n",
      "\tgpu_power_usage = 218490\n",
      "\t132\n",
      "\tarea = 4375.5\n",
      "\tgpu_temperature = 45\n",
      "\n",
      "resnet50 128 nvidia-gpu-device-plugin-bdtt6\n",
      "\t128\n",
      "\tarea = 226.0\n",
      "\tgpu_utilization = 99\n",
      "\t128\n",
      "\tarea = 2500.0843958105834\n",
      "\tgpu_memory = 95.37514802909828\n",
      "\t128\n",
      "\tarea = 4841477.5\n",
      "\tgpu_power_usage = 275064\n",
      "\t128\n",
      "\tarea = 3883.0\n",
      "\tgpu_temperature = 44\n",
      "\n",
      "resnet50 256 nvidia-gpu-device-plugin-sn4v2\n",
      "\t78\n",
      "\tarea = 614.0\n",
      "\tgpu_utilization = 98\n",
      "\t78\n",
      "\tarea = 2487.1974054536227\n",
      "\tgpu_memory = 95.37514802909828\n",
      "\t78\n",
      "\tarea = 3219675.0\n",
      "\tgpu_power_usage = 232619\n",
      "\t79\n",
      "\tarea = 2708.0\n",
      "\tgpu_temperature = 54\n",
      "\n",
      "resnet50 32 nvidia-gpu-device-plugin-7q5x9\n",
      "\t128\n",
      "\tarea = 2.0\n",
      "\tgpu_utilization = 1\n",
      "\t128\n",
      "\tarea = 2490.357346088186\n",
      "\tgpu_memory = 95.37514802909828\n",
      "\t128\n",
      "\tarea = 3770137.0\n",
      "\tgpu_power_usage = 54300\n",
      "\t128\n",
      "\tarea = 4094.0\n",
      "\tgpu_temperature = 38\n",
      "\n",
      "resnet50 64 nvidia-gpu-device-plugin-vllzp\n",
      "\t126\n",
      "\tarea = 322.0\n",
      "\tgpu_utilization = 96\n",
      "\t126\n",
      "\tarea = 2501.2076867473575\n",
      "\tgpu_memory = 95.37514802909828\n",
      "\t126\n",
      "\tarea = 4771818.0\n",
      "\tgpu_power_usage = 248519\n",
      "\t126\n",
      "\tarea = 4165.5\n",
      "\tgpu_temperature = 43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_grafana_info(values, label='info'):\n",
    "    if all(v == 0 for v in values):\n",
    "        print('\\tERROR')\n",
    "    else:\n",
    "        print('\\t' + label + ' = ' + str(max(values)))\n",
    "\n",
    "for index, row in gpu_info.iterrows():\n",
    "    print(row['model'], row['batch-size'], row['nvidia-plugins'])\n",
    "    tolerance_min = 3\n",
    "    \n",
    "    gpu_utilization = get_grafana_info(row, grafana_gpu_utilization, tolerance_min)\n",
    "    print_grafana_info(gpu_utilization, 'gpu_utilization')\n",
    "    gpu_info.at[index, 'gpu-utilization'] = gpu_utilization\n",
    "    \n",
    "    gpu_memory = get_grafana_info(row, grafana_gpu_memory)\n",
    "    print_grafana_info(gpu_memory, 'gpu_memory')\n",
    "    gpu_info.at[index, 'gpu-memory'] = gpu_memory\n",
    "        \n",
    "    gpu_power_usage = get_grafana_info(row, grafana_gpu_power_usage, tolerance_min)\n",
    "    print_grafana_info(gpu_power_usage, 'gpu_power_usage')\n",
    "    gpu_info.at[index, 'gpu-power-usage'] = gpu_power_usage\n",
    "    \n",
    "    gpu_temperature = get_grafana_info(row, grafana_gpu_temperature, tolerance_min)\n",
    "    print_grafana_info(gpu_temperature, 'gpu_temperature')\n",
    "    gpu_info.at[index, 'gpu-temperature'] = gpu_temperature\n",
    "        \n",
    "    print()\n",
    "\n",
    "gpu_info.to_csv('results/experiments-with-grafana.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "gitlab-registry.cern.ch/ai-ml/images/kale-custom",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
